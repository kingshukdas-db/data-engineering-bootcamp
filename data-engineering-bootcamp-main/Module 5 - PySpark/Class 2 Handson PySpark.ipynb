{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95116c4d-d8d9-4a0d-965b-a9b6efa21d8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Class 4 of PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d26423bf-ab96-40cf-9b0e-9e727eec83ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataX_Bootcamp\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f97c4a7-9312-43b4-a133-549c398873ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#create Realistic Dataframe of Employee\n",
    "\n",
    "data={\n",
    "        (\"Alice\",\"IT\",50000),\n",
    "        (\"Anurag\",\"Data Engineer\",100000),\n",
    "        (\"Bob\",\"HR\",40000),\n",
    "        (\"Stuti\",\"Recruiter\",150000),\n",
    "        (\"Ayushi\",\"HR\",30000),\n",
    "        (\"Ankur\",\"IT\",510000),\n",
    "        (\"Shruti\",\"Finance\",650000),\n",
    "        (\"Shalini\",\"Finance\",850000),\n",
    "}\n",
    "\n",
    "\n",
    "column=[\"Name\",\"Department\",\"Salary\"]\n",
    "\n",
    "df=spark.createDataFrame(data,column)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a969828c-ddb1-4d21-8687-9db116b66b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Select and filter on the Dataframe Created\n",
    "display(df.select(\"Name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cec2de9-9bf4-4c67-b1d9-272d54a4622f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.select(\"Name\",\"Salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f753c519-8a3d-4cbb-a534-3fdaea82ffd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#filter rows based on salary\n",
    "\n",
    "display(df.filter(df.Salary>100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a302c271-4763-459e-a28f-a2a0dd33258a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(df.filter(df['Salary']>100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29170752-f2be-4bf4-9eea-e4c521dd4eb9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Apply multiple filters \n",
    "\n",
    "display(df.filter((df[\"Department\"] == \"Finance\") & (df[\"Salary\"] > 60000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2d950d7-e848-4518-b62d-429461147ee8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Create a Derived Column\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#Add 10% Bonus to everyone \n",
    "df=df.withColumn(\"Bonus\",col(\"Salary\")*0.1)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd45d57b-f5f1-4598-9262-00249fa17ce9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Group by and Aggregation\n",
    "\n",
    "#average of salary by department \n",
    "\n",
    "df.groupBy(\"Department\").avg(\"Salary\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b16851c7-a1a1-474c-aebe-ca51cd8f0045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Apply Multiple aggregration \n",
    "from pyspark.sql.functions import avg, max, min\n",
    "\n",
    "display(df.groupBy(\"Department\").agg(\n",
    "    avg(\"Salary\").alias(\"Avg_Salary\"),\n",
    "    max(\"Salary\").alias(\"Max_Salary\"),\n",
    "    min(\"Salary\").alias(\"Min_Salary\")\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fd09e1c-4318-480a-9504-a31b17b70d03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#join() â€“ Combine Two DataFrames\n",
    "\n",
    "# Create dept code mapping\n",
    "dept_data = [(\"IT\", 101), (\"HR\", 102), (\"Finance\", 103)]\n",
    "dept_columns = [\"Department\", \"Dept_Code\"]\n",
    "\n",
    "df_dept = spark.createDataFrame(dept_data, dept_columns)\n",
    "\n",
    "# Join operation\n",
    "joined_df = df.join(df_dept, on=\"Department\", how=\"inner\")\n",
    "display(joined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "654fb6a2-365b-4be5-b3a3-f02581795a60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Transformation V/S Action \n",
    "\n",
    "\n",
    "#Transformation\n",
    "filtered = df.filter(df[\"Salary\"] > 50000)\n",
    "\n",
    "#Action\n",
    "filtered.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fccccb45-052b-428f-98ed-6004cfa80076",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Student Practice Assignment\n",
    "\n",
    "\n",
    "_ðŸ“‚ Build a DataFrame with the following schema:\n",
    "Name, Department, Salary, Location_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a15f65fe-a763-48b9-ac54-17d495598c03",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Sample data\n",
    "data = [\n",
    "    (\"Anurag\", \"IT\", 70000, \"Bangalore\"),\n",
    "    (\"Priya\", \"HR\", 55000, \"Mumbai\"),\n",
    "    (\"Ravi\", \"Finance\", 65000, \"Delhi\"),\n",
    "    (\"Sneha\", \"IT\", 60000, \"Hyderabad\")\n",
    "]\n",
    "\n",
    "columns = [\"Name\", \"Department\", \"Salary\", \"Location\"]\n",
    "\n",
    "df_task = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Task 1: Filter IT employees with salary > 60K\n",
    "df_task.filter((col(\"Department\") == \"IT\") & (col(\"Salary\") > 60000)).show()\n",
    "\n",
    "# Task 2: Add column \"Hike_Amount\" as 15% of salary\n",
    "df_task = df_task.withColumn(\"Hike_Amount\", col(\"Salary\") * 0.15)\n",
    "df_task.show()\n",
    "\n",
    "# Task 3: Group by Department and show average salary\n",
    "df_task.groupBy(\"Department\").avg(\"Salary\").show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Class 2 Handson PySpark",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
